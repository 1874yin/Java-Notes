## 雪花算法

单体项目中一个表中的主键 ID 都是自增的，MySQL 利用 autoincrement 实现，Oracle 利用序列实现。单表数据量上来以后就要进行水平分表（阿里Java开发建议单表大于 500w 进行分表），一张表拆分成多张表，如果按照以前的自增来做主键 ID，就会出现 ID 重复。所以就需要分布式 ID。

分布式 ID 必须具备的特点：

- 高性能
- 单调递增
- 全局唯一

### 方案

1. 数据库表

   在某个库专门维护一张表，无论哪个表需要自增 ID，都去查这个表的记录，用 `for update` 锁表，取到的值 +1，返回以后再把值记录到表中。该方法仅适用于并发量较小的项目。

2. Redis

   Redis 是单线程，可以在 Redis 中维护一个键值对，然后哪个表需要直接去 Redis 中取值然后 +1。

   由于是单线程，对高并发的支持不高，只适合并发量小的项目。

3. UUID

   使用 UUID 作为不重复的主键 ID，但是 UUID 是无序的字符串，会导致主键索引失效。另外 UUID 使用字符存储，查询效率低，占用空间大。

4. 雪花算法

   使用 64 位 long 类型的数据存储 ID。

   - 最高一位是符号位，一般是正数，也就是0
   - 41位存储毫秒级时间戳，`System.currentTimeMillis()` 生成的时间转换为二进制刚好41位
   - 10位存储机器码（包括 5位 dataCenterId，5位 workerId）
   - 12位存储序列号 sequence，序列号自增

   所以，`1+41+10+12=64` 刚好是 long 类型的大小。

   ![img](https://upload-images.jianshu.io/upload_images/13382703-b64e38457ddd13e2.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1021/format/webp)

### 实现

```java
public class SnowFlake {
    /**
     * 时间戳起始位置
     */
    private final static long TIMESTAMP_START = 1709603659000L; //  2024.0305 09:54
    /**
     * 各部分占用比特数
     */
    private final static long DATA_CENTER_BIT = 5L;		// 数据中心
    private final static long WORKER_BIT = 5L;			// worker
    private final static long SEQUENCE_BIT = 12L;		// 序号
    /**
     * 各部分最大值
     */
    private final static long MAX_DATA_CENTER = ~(-1 << DATA_CENTER_BIT);
    private final static long MAX_WORKER = ~(-1 << WORKER_BIT);
    private final static long MAX_SEQUENCE = ~(-1 << SEQUENCE_BIT);
    /**
     * 各部分左移位数
     */
    private final static long WORKER_LEFT = SEQUENCE_BIT;
    private final static long DATA_CENTER_LEFT = WORKER_LEFT + WORKER_BIT;
    private final static long TIMESTAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT; 
    /**
     * 各种初始值
     */
    private final long dataCenterId;
    private final long workerId;
    
    private long sequence = 0L;
    private long last_timestamp = -1L;
    
    public SnowFlake(long dataCenterId, long workerId) {
        if (dataCenterId > MAX_DATA_CENTER || dataCenterId < 0) {
            throw new IllegalArgumentException(
            		String.format("DataCenterId can't be greater than %d or less than 0. DataCenterId: %d",
                    	MAX_DATA_CENTER, dataCenterId));
        }
        if (workerId > MAX_WORKER || workerId < 0) {
            throw new IllegalArgumentException(
                    String.format("WorkerId can't be greater than %d or less than 0. WorkerId: %d",
                            MAX_WORKER, workerId));
        }
        this.dataCenterId = dataCenterId;
        this.workerId = workerId;
    }
    
    /**
     * 获取当前时间戳
     */
    private long getNowTime() {
        return System.currentTimeMillis();
    }
    
    /**
     * 获取下一个时间戳
     */
    private long getNextTime() {
        long nowTime = getNowTime();
        while (nowTime < lastTimestamp) {
            nowTime = getNowTime();
        }
        return nowTime;
    }
    
    /**
     * 生成 ID
     */
    prulic synchronized long nextId() {
        long currentTimestamp = getNextTime();
        if (currentTimestamp < this.lastTimestamp) {
            throw new RuntimeException("System clock move backward. Refuse to generate ID");
        }
        if (currentTimestamp == this.lastTimestamp) {
            this.sequence = (this.sequence + 1) & MAX_SEQUENCE;
            if (this.sequence == 0L) {
                currentTimestamp = getNextTime();
            }
        } else {
            this.sequence = 0L;
        }
        this.lastTimestamp = currentTimestamp;
        
        return (currentTimestamp - TIMESTAMP_START) << TIMESTAMP_LEFT
            	| this.dataCenterId << DATA_CENTER_LEFT
            	| this.workerId << WORKER_LEFT
            	| this.sequence;
    }
    
    public static void main(String[] args) {
        SnowFlake sf = new SnowFlake(2, 6);
        for (int i = 0; i < ~(-1L << 5); i++) {
            System.out.println(sf.nextId());
        }
    }

```

#### 输出

```shell
32721841971200
32721841971201
32721841971202
32721841971203
32721841971204
32721841971205
32721841971206
32721841971207
32721841971208
32721841971209
32721841971210
32721841971211
32721841971212
32721841971213
32721841971214
32721841971215
32721841971216
32721841971217
32721841971218
32721841971219
32721841971220
32721841971221
32721841971222
32721841971223
32721841971224
32721841971225
32721841971226
32721841971227
32721841971228
32721841971229
32721841971230

Process finished with exit code 0

```



雪花算法可以在不同机器上生成不重复递增 ID，需要防止服务器时间回拨导致的 ID 生成重复。

- 41 bit 可以表示 2 ^ 41 - 1 个数字，转换为单位年则是 `(2^41) / (1000 * 60 * 60 * 24 * 365) = 69 年
- 10 bit 的工作机器 ID ，用来记录工作机器的 ID。可以部署在 2 ^ 10 = 1024 个节点上。2 ^ 5 - 1 = 31，即可以用 0-31 的数字来表示 dataCenterId 和 workerId
- 12 bit 序列号用来记录同一毫秒内产生的不同 ID。2 ^ 12 - 1 = 4095，同一机器同一毫秒内可以产生 4095 个 ID 序号

#### NOTE

1. `~(-1 << 5)` 用来计算 5 位比特所能表示的最大数字，等同于 `2 ^ 5 -1` 
2. 任何数 `n <= m`，`n & m` 的结果都等于 n 。`(m + 1) & m `  结果等于 0。`&` 是按位与操作符，在二进制位上，同位如果都为1，则该位结果为1，否则为0。如 `110011 & 100010 = 100010` 
3. 加上 `TIMESTAMP_START` 来减小时间戳起点，可以增加该算法可使用年限
4. 使用 `<<` 左移操作符，在 64 位的二进制位上移动后，后方的比特位便留空了（都为0），这时候使用 `|` 操作符，效果相当于拼接二进制。

## 补充：Leaf——美团点评分布式ID生成系统

业务系统对 ID 号的要求：

1. 全局唯一性：唯一标识的基本要求。
2. 趋势递增：多数 RDBMS 使用 B-tree 的数据结构来存储索引数据，主键应该尽量使用有序主键保证写入性能。
3. 单调递增：保证下一个 ID 一定大于上一个 ID，例如事务版本号、IM 增量消息、排序等特殊需求。
4. 信息安全：如果 ID 是连续的，容易被恶意爬取，直接按照顺序下载指定 URL 即可；如果是订单号，还会被猜出一天订单数量。在一些应用场景下，需要 ID 无规则、不规则。

对 ID 号生成系统的可用性要求：

1. 平均延迟和 TP999 延迟都要尽可能低
2. 可用性5个9
3. 高 QPS

### 常见方法介绍

#### UUID

包含32个15进制数字，以连字号分为五段，形式为 8-4-4-4-12 的36个字符。

优点：

- 性能非常高：本地生成，没有网络消耗

缺点：

- 不易于存储：UUID 太长，16字节128位
- 信息不安全：基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露
- ID 作为主键在特定的环境会存在一些问题，比如做 DB 主键就非常不适用
  1. MySQL 官方明确建议主键要尽量越短越好
  2. 对 MySQL 索引不利：如果作为数据库主键，UUID 的无序性会引起数据位置频繁变动，严重影响性能

#### 类 SnowFlake 方案

将 64-bit 分别划分成多段，分开来标识机器、时间等。

优点：

- 毫秒数在高位，自增序列在低位，保证了趋势递增
- 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高
- 可以根据自身业务特性分配 bit 位，非常灵活

缺点：

- 强依赖机器时钟，如果机器始终回拨，会导致发号重复或者服务处于不可用状态

#### 数据库生成

以 MySQL 为例，给字段设置 `auto_increment_increment` (增量，也就是增长步长 step) 和 `auto_increment_offset` (初始值，增长起点) 来保证 ID 自增，通过下列 SQL 读写得到 ID 号：

```mysql
begin;
REPLACE INFO Tickets64 (stub) VALUES ('a');
SELECT LAST_INSERT_ID();
commit;
```

优点：

- 非常简单，利用现有数据库系统的功能实现，成本小，有 DBA 专业维护
- ID 号单调自增，可以实现一些对 ID 有特殊要求的业务

缺点：

- 强依赖 DB，当 DB 异常时，整个系统不可用，属于致命问题。配置主从复制可以尽可能增加可用性，但是难以保证主从切换时的数据一致性
- ID 发号性能瓶颈限制在单台 MySQL 的读写性能

水平扩展：多部署几台机器，每台机器设置不一样的起始值，步长 step 和机器数相等。比如三台机器，设置 step 为3

TicketServer1 生成的 ID 为

```
1, 4, 7, 10, 13...
```

TicketServer2 生成的 ID 为

```
2, 5, 8, 11, 14...
```

TicketServer3 生成的 ID 为

```
3, 6, 9, 12, 15...
```

缺点是如果需要进行水平扩展比较困难；ID 没有了单调递增的特性，只能趋势递增；每次获取 ID 都得读写一次数据库，数据库压力还是很大。

#### Leaf 方案实现

##### Leaf-segment数据库方案

在使用数据库方案上，做了如下改变：

- 将每次获取 ID 都得读写一次数据库，改为利用 proxy-server 批量获取，每次获取一个 segment 号段的值，用完之后再去数据库获取新的号段，大大减轻数据库压力
- 各个业务不同的发号需求用 biz_tag 字段来区分，每个 biz_tag 的 ID 获取相互隔离，互不影响。如果日后有扩容需求，只需要对 biz_tag 分库分表

数据库表设计如下：

```mysql
+-------------+--------------+------+-----+-------------------+-----------------------------+
| Field       | Type         | Null | Key | Default           | Extra                       |
+-------------+--------------+------+-----+-------------------+-----------------------------+
| biz_tag     | varchar(128) | NO   | PRI |                   |                             |
| max_id      | bigint(20)   | NO   |     | 1                 |                             |
| step        | int(11)      | NO   |     | NULL              |                             |
| desc        | varchar(256) | YES  |     | NULL              |                             |
| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
+-------------+--------------+------+-----+-------------------+-----------------------------+
```

- biz_tag 用来区分业务
- max_id 表示当前所被分配的 ID 号段的最大值
- step 表示每次分配号段的长度

原来获取 ID 每次都需要请求数据库，现在只要把 step 设置得足够大，只有当号段内的 ID 被用完，才会重新读取一次数据库，读写频率降低到 1/step

现在假设数据库中一条记录为

```mysql
+----------+------+----+------+------------+
| biz_tag  |max_id|step| desc | update_time| 
+----------+-----------+------+------------+
| test_tag | 3001 |1000|      |            |
+----------+------+----+------+------------+
```

test_tag 在第一台机器上是 1~1000 的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段应该为 3001~4000。同时数据库中 test_tag 对应的 max_id 应该被更新为 4001，更新的 SQL 语句如下：

```mysql
Begin
UPDATE table SET max_id = max_id+step WHERE biz_tag = 'test_tag'
SELECT biz_tag, max_id, step FROM table WHERE biz_tag = 'test_tag'
Commit
```

优点：

- Leaf 服务可以很方便地线性扩展
- ID 号码趋势递增
- 容灾性高：Leaf 内部有号段缓存，即使 DB 宕机，短时间内也能对外提供服务
- 可以自定义 max_id 大小，方便迁移

缺点：

- ID 号码不够随机，能够泄露发号数量，不太安全
- TP999数据波动大，当号码使用完后会 hang 在更新数据库的 I/O 上
- DB 宕机会造成整个系统不可用

**双 Buffer 优化**

对于第二个缺点，Leaf 是在号段消耗完的时候去取新号段，也就是说 ID 到达临界点时，获取新 ID 的时间取决于从 DB 取回新号段的时间，并且这期间的业务请求会因为新号段没有取回来，导致线程阻塞。

我们可以在号段消耗到达某个值（比如10%）的时候，异步去数据库请求下一个号段，并加载到内存中。当前号段全部用完，如果下个号段准备好了，则切换到下个号段为当前号段接着下发 ID，循环反复。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/f2625fac.png)

- 每个 biz_tag 都有消费速度监控，推荐 segment 长度设置为服务高发期 QPS 的 600倍（10分钟），即使 DB 宕机，服务也能维持 10~20 分钟
- 每次请求来临，判断下个号段状态，从而更新新号段，偶尔的网络抖动不会影响下个号段的更新

**Leaf 高可用容灾**

对于 “DB可用性”问题，采用一主两从的方式，同时分机房部署，Master 和 Slave 之间采用半同步方式同步数据。同时 Leaf 服务分 IDC 部署，服务调用的时候，根据负载均衡算法会优先调用同机房的 Leaf 服务。

##### Leaf-snowflake 方案

Leaf-segment 方案可以生成趋势递增的 ID，同时 ID 号是可计算的，不适用于订单 ID 生成场景，竞争对手在两天中午分别下单，通过订单 ID 号相减就能大致计算出公司一天的订单量。

Leaf-snowflake 完全沿用 snowflake 方案的 bit 位设计，即 "1+41+10+12" 的方式组装 ID 号。对于 workerID 的分配，当服务集群数量较小的情况下，手动配置。Leaf 服务规模较大，使用 ZooKeeper 持久顺序节点的特性自动分配 workerID。步骤：

1. 启动 Leaf-snowflake 服务，连接 Zookeeper，在 leaf_forever 父节点下检查自己是否已经注册过
2. 注册过直接取回自己的 workerID，启动服务
3. 未注册过，在该父节点下创建一个持久顺序节点，创建成功后取回顺序号当做自己的 workerID，启动服务

**弱依赖 Zookeeper**

除了每次去 ZK 拿数据，workerID 也会缓存在本机文件系统上。当 ZK 出现问题，机器也要重启时，能保证服务正常启动，一定程度上提高了 SLA。

**解决时钟问题**

雪花算法依赖时间，如果机器的时钟发生了回拨，就会可能生成重复的 ID 号，需要解决时钟回退问题。

1. 在上一步中取得 workerID 之后，如果写过 zk 的 leaf_forever 节点，则用系统时间与 leaf_forever/${self} 节点记录时间做比较，若小于 leaf_forever/${self} 则认为机器时间发生了大步长回拨，服务启动失败并报警
2. 若未写过，证明是新服务节点，直接创建 leaf_forever/${self} 并写入自身系统时间。取 leaf_temporary 下所有临时节点（运行中的 Leaf-snowflake 节点）的服务 IP:Port，通过 RPC 请求得到所有节点的系统时间，计算平均值
3. 如果 abs(系统时间 - 节点时间平均值) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点 leaf_temporary/${self} 维持租约
4. 否则认为本机系统时间发生大步长偏移，启动失败并报警
5. 每隔一段时间（3s）上报自身系统时间写入 leaf_forever/${self}

机器工作时 NTP 同步也会造成秒级回退，建议直接关闭 NTP 同步。可以在时钟回拨的时候直接不提供服务，返回 ERROR_CODE，等时钟追上。

或者做一层重试，然后上报报警系统。更或者是发现有时钟回拨之后自动摘除本身节点并报警。

```java
// 发生回拨，此刻时间小于上次发号时间
if (timestamp < lastTimestamp) {
    long offset = lastTimestamp - timestamp;
    if (offset <= 5) {
        try {
            wari(offset << 1); // 等待两倍时间
            timestamp = timeGen();
            if (timestamp < lastTimestamp) {
                throw ClockBackwardsException(timestamp);
            }
        } catch (InterruptedException e) {
            throw e;
        }
    } else {
        throw ClockBackwardsException(timestamp);
    }
}
// 分配 ID
```



